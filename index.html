<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NQ304D3RY1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-NQ304D3RY1');
    </script>
    <title>Nhan Phan</title>
    <meta charset="utf-8">
    <meta name="description" content="Nhan Phan">
    <meta name="author" content="Nhan Phan">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="refresh" content="600">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;0,700;1,400;1,600;1,700&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" type="text/css" href="style_small.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
        integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://vjs.zencdn.net/8.16.1/video-js.css" rel="stylesheet" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="//toolness.github.io/p5.js-widget/p5-widget.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/addons/p5.sound.min.js"></script>


</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPJHJ1TMV0"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-ZPJHJ1TMV0');
</script>

<body>
    <div class="page-container">
        <div class="bg" id="large-bg">
            <img src="assets/000025.jpeg">
        </div>

        <div class="bg" id="mobile-bg">
            <img src="assets/mobile-bg.png">
        </div>
        <div class="container-offset">
            <section id="bio">
                <div class="nav-header">
                    <h1>Nh√¢n Phan</h1>
                </div>
                <div style="text-align:justify">
                    <p>
                        Nhan is a technologist and educator. Emerged from photography, his projects
                        explore the application of coding in len-based practices. He makes photos, zines, and prints as
                        a shelter for his memory, dream, and fantasy. His works have been featured in Ho Chi Minh City,
                        New York, Bangkok, and Kuala Lumpur.
                        <br><br>
                        Nhan is a mentor of the Processing Fellowship 2024. He is also a former fellow of the
                        Processing Fellowship 2023.
                    </p>
                    <!-- <p>
                        Born to the era of Yahoo! 360 Blog, Flickr, and Tumblr, I grew up making blogs, scrapbooks, and
                        CD covers from photos I took and from the net. To me, photos are beautiful, sentimental, and
                        nostalgic. The web has changed ever since. The new medium of coding allows me to look back into my
                        archival practice in a different way but that wistful feeling shall never fade.
                    </p> -->

                    <p>
                        IG @ <a href="https://instagram.com/nhaninsummer">nhaninsummer</a>
                        <br>Gmail @ <a href="mailto:nhaninsummer@gmail.com">nhaninsummer</a>
                    </p>
                </div>
            </section>

            <!-- <section id="bio">
                <div class="nav-header">
                    <h1>t√¥i</h1>
                </div>
                <div style="text-align:justify">
                    <p>
                        B·∫•t l·ª±c v·ªõi th·ªùi gian, Nh√¢n s√°ng t√°c nh∆∞ m·ªôt c√°ch ƒë·ªÉ n√≠u gi·ªØ, h·ªìi t∆∞·ªüng, s·ªëng l·∫°i, v√† b√π ƒë·∫Øp
                        cho nh·ªØng gi√¢y ph√∫t k·ª∑ ni·ªám ƒë√£ ph√¥i pha, tan bi·∫øn, v·ª•t m·∫•t, phai nh·∫°t v√†o dƒ© v√£ng. T·ª´ nh·ªØng c·∫£m
                        x√∫c v√† chi√™m nghi·ªám v·ªÅ ch·∫∑ng ƒë∆∞·ªùng m√¨nh s·ªëng v√† l·ªõn l√™n, c√°c t√°c ph·∫©m v√† th·ª±c h√†nh c·ªßa Nh√¢n
                        th∆∞·ªùng g·∫Øn li·ªÅn v·ªõi c·ªôi ngu·ªìn gia ƒë√¨nh, vƒÉn ho√° √Å ƒê√¥ng, nh√¨n nh·∫≠n v·ªÅ b·∫£n th√¢n, v·ªÅ c∆° th·ªÉ, t√≠nh
                        d·ª•c, v√† nhung nh·ªõ v·ªÅ m·ªëi quan h·ªá v·ªõi nh·ªØng ng∆∞·ªùi ƒëi qua cu·ªôc ƒë·ªùi anh.

                        <br><br><i>‚ÄúNh∆∞ th·ªÉ trong l√≤ng t√¥i, trong tr√°i tim t√¥i c√≥ c·∫£ m·ªôt bi·ªÉn tr·ªùi n·ªói ni·ªÅm ‚Äî ƒëong ƒë·∫ßy t√¨nh y√™u,
                        n·ªói nh·ªõ, si m√™, v√† ƒë·∫Øm say cho m·ªçi s·ª± tr√™n ƒë·ªùi m√† t√¥i kh√¥ng bi·∫øt ph·∫£i r√≥t ƒëi ƒë√¢u.‚Äù</i>

                        <br><br>Nh√¢n th·ª±c h√†nh li√™n ng√†nh, ch·ªß y·∫øu tr√™n ch·∫•t li·ªáu h√¨nh ·∫£nh v√† k·ªπ thu·∫≠t (l·∫≠p tr√¨nh). Ngo√†i ra anh
                        c√≤n th·ª±c h√†nh in, s·∫Øp ƒë·∫∑t, tr√¨nh di·ªÖn, v√† vi·∫øt. Hi·ªán t·∫°i anh ƒëang gi·∫£ng d·∫°y v·ªÅ l·∫≠p tr√¨nh t·∫°i TPHCM. C√°c s√°ng t√°c v√† chia s·∫ª v·ªÅ gi√°o d·ª•c c·ªßa anh
                        t·ª´ng xu·∫•t hi·ªán ·ªü TPHCM, New York, Bangkok, v√† Kuala Lumpur. 
                        
                        <br><br>Nh√¢n ƒëang l√† mentor c·ªßa Processing Fellowship 2024. B·∫£n th√¢n anh c≈©ng t·ª´ng l√† fellow c·ªßa ch∆∞∆°ng
                        tr√¨nh nƒÉm 2023.
                    </p>
                </div>
            </section> -->

            <section id="navigation">
                <div class="nav">
                    <div class="nav-content-block">
                        <h2 class="nav-sub-header">Teach
                        </h2>
                        <div class="nav-content pl-4 pb-3">
                            <p class="mb-1"><a href="https://codesurfing.club" target="_blank">(2023~) CodeSurfing</a>
                            </p>
                            <p class="mb-1"><a href="https://processingfoundation.org/fellowships/fellowships-2023"
                                    target="_blank">(2023) Processing Fellowship</a></p>
                            <p class="mb-1"><a href="#" target="_blank">(2019~2023) Machine Learning</a></p>
                        </div>
                    </div>

                    <div class="nav-content-block">
                        <h2 class="nav-sub-header">Selected Works</h2>
                        <div class="nav-content pl-4 pb-3">
                            <p class="mb-1"><a href="#tieng-viet-1">(2024) √¢m ti·∫øt ti·∫øng Vi·ªát 1</a></p>
                            <p class="mb-1"><a href="#tieng-viet-2">(2024) √¢m ti·∫øt ti·∫øng Vi·ªát 2</a></p>
                            <p class="mb-1"><a href="#wa">(2024) Âíå</a></p>
                            <p class="mb-1"><a href="#sensory-narratives">(2023) sensory narratives</a></p>
                            <p class="mb-1"><a href="#beach-pocket">(2022) beach pocket</a></p>
                            <p class="mb-1"><a href="#gai-gia">(2022) „Ç¨„Ç§„Ç∏„É£Âà•Â∫ú</a></p>
                            <p class="mb-1"><a href="#live-laugh-dick">(2022) live. laugh. dick(s).</a></p>
                        </div>
                    </div>

                    <div class="nav-content-block">
                        <h2 class="nav-sub-header">Coding Practice</h2>
                        <div class="nav-content pl-4 pb-3">
                            <p class="mb-1"><a href="#wes-anderson">(2021) wes anderson</a></p>
                            <p class="mb-1"><a href="#esrgan">(2020) esrgan</a></p>
                            <p class="mb-1"><a href="#viet-ocr">(2020) viet ocr</a></p>
                            <p class="mb-1"><a href="#amazon">(2019) amazon</a></p>
                        </div>
                    </div>

                    <!-- <div class="nav-content-block">
                        <h2 class="nav-sub-header"><a href="before2020.html"
                                style="text-decoration:none!important; color:rgb(148, 58, 233)">Before 2020 </a></h2>
                    </div> -->

                </div>
            </section>

            <section id="tieng-viet-1">
                <h2>
                    (2024) √Çm ti·∫øt ti·∫øng Vi·ªát ‚éØ Vol. 1
                </h2>
                <div class="tag-container">
                    <span class='tag'>Python</span>
                </div>

                <p>
                    √Çm ti·∫øt ti·∫øng Vi·ªát (Vietnamese syllable) is a collaborative research of Yui Nguy·ªÖn
                    (<i>researcher</i>), Nh√¢n Phan (<i>technologist</i>), and
                    Ng·ªçc V√µ (<i>visual designer</i>) to deconstruct and understand Vietnamese language from its
                    syllables. From that, we reflect on how Vietnamese language
                    invokes image, feeling, and emotion through its pronunciation.
                </p>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-01.png"><img
                        src="assets/tieng-viet-1/TV-SO1-01.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-02.png"><img
                        src="assets/tieng-viet-1/TV-SO1-02.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-03.png"><img
                        src="assets/tieng-viet-1/TV-SO1-03.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-04.png"><img
                        src="assets/tieng-viet-1/TV-SO1-04.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-05.png"><img
                        src="assets/tieng-viet-1/TV-SO1-05.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-06.png"><img
                        src="assets/tieng-viet-1/TV-SO1-06.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-07.png"><img
                        src="assets/tieng-viet-1/TV-SO1-07.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-08.png"><img
                        src="assets/tieng-viet-1/TV-SO1-08.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-09.png"><img
                        src="assets/tieng-viet-1/TV-SO1-09.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-1/TV-SO1-10.png"><img
                        src="assets/tieng-viet-1/TV-SO1-10.png"></a>
            </section>
            <section id="tieng-viet-2">
                <h2>
                    (2024) √Çm ti·∫øt ti·∫øng Vi·ªát ‚éØ Vol. 2
                </h2>
                <div class="tag-container">
                    <span class='tag'>p5.js</span>
                </div>

                <p>
                    √Çm ti·∫øt ti·∫øng Vi·ªát (Vietnamese syllable) is a collaborative research of Yui Nguy·ªÖn
                    (<i>researcher</i>), Nh√¢n Phan (<i>technologist</i>), and
                    Ng·ªçc V√µ (<i>visual designer</i>) to deconstruct and understand Vietnamese language from its
                    syllables. From that, we reflect on how Vietnamese language
                    invokes image, feeling, and emotion through its pronunciation.
                </p>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-01.png"><img
                        src="assets/tieng-viet-2/TV-SO2-01.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-02.png"><img
                        src="assets/tieng-viet-2/TV-SO2-02.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-03.png"><img
                        src="assets/tieng-viet-2/TV-SO2-03.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-04-2.gif"><img
                        src="assets/tieng-viet-2/TV-SO2-04-2.gif"></a>

                <p>
                    Try it yourself at <a href="https://tiengviet.netlify.app/"
                        target="_blank">https://tiengviet.netlify.app/</a>
                </p>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-05-2.gif"><img
                        src="assets/tieng-viet-2/TV-SO2-05-2.gif"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-06.png"><img
                        src="assets/tieng-viet-2/TV-SO2-06.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-07.png"><img
                        src="assets/tieng-viet-2/TV-SO2-07.png"></a>
                <a data-fslightbox="gallery" href="assets/tieng-viet-2/TV-SO2-08.png"><img
                        src="assets/tieng-viet-2/TV-SO2-08.png"></a>
            </section>


            

            <section id="wa">
                <h2>
                    (2024) Âíå
                </h2>
                <div class="tag-container">
                    <span class='tag'>p5.js</span> <span class='tag'>work in progress</span>
                </div>

                <p>
                    On the first days of the year, Vietnamese go to temple to ask for a word. A simple, single, yet
                    intricate word that marks our intention for the whole year ahead.

                    <br><br>Many ask for ‚ÄúL·ªôc ‚Äî Á¶Ñ‚Äù to call for abundance, some ask for ‚ÄúNh·∫´n ‚Äî Âøç‚Äù to remind themselves
                    about the
                    value of steadiness.

                    <br><br>I always ask for ‚ÄúHo√† ‚Äî Âíå‚Äù.

                    <br><br>Ho√† Âíå is the state of this universe where everything aligns.
                    ‚Äî ‚ÄúThi√™n th·ªùi, ƒë·ªãa l·ª£i, nh√¢n ho√†‚Äù (As above, so below).

                    <br>Ho√† Âíå calls for the mediation between human and non-human.

                    <br>Ho√† Âíå calls for Peace.

                    <br><br>Based on that one word "Âíå", this work-in-progress attempts to create a meditative space from
                    past images of sacred places I have been to.
                </p>

                <a data-fslightbox="gallery" href="assets/wa/3.png"><img src="assets/wa/3.png"></a>
                
                <div class="row">
                    <div class="col-4">
                        <a data-fslightbox="gallery" href="assets/wa/sample/2.JPG"><img
                            src="assets/wa/sample/2.JPG"></a>
                    </div>
                    <div class="col-4">
                        <a data-fslightbox="gallery" href="assets/wa/sample/1.JPG"><img
                                src="assets/wa/sample/1.JPG"></a>
                    </div>
                    <div class="col-4">
                        <a data-fslightbox="gallery" href="assets/wa/sample/0.JPG"><img
                            src="assets/wa/sample/0.JPG"></a>
                    </div>
                </div>
                <p id="portrait-guide"><i>curtain draft</i></p>

                <a data-fslightbox="gallery" href="assets/wa/1.png"><img src="assets/wa/1.png"></a>
                <a data-fslightbox="gallery" href="assets/wa/0.png"><img src="assets/wa/0.png"></a>
                <a data-fslightbox="gallery" href="assets/wa/2.png"><img src="assets/wa/2.png"></a>

            </section>

            <section id="sensory-narratives">
                <h2>
                    (2023) Sensory Narratives
                </h2>

                <div class="tag-container">
                    <span class='tag'>p5.js</span> <span class='tag'>teach</span>
                    <img src="assets/jump/jump_0.png">
                </div>

                <p>
                    ‚ÄúThu ƒÉn mƒÉng gi√°, ƒë√¥ng ƒÉn tr√∫c.
                    <br>Xu√¢n t·∫Øm h·ªì sen, h·∫° t·∫Øm ao.‚Äù
                    <br>- Nguy·ªÖn Khuy·∫øn
                </p>

                <p>
                    Sensory Narratives is a curriculum that Nhan developed during his fellowship with Processing
                    Foundation in 2023.
                    The course guides students to use creative coding as a way to manifest the harmony between human and
                    our
                    surrounding nature.

                    The curriculum is designed to nurture individual artistry while offering a cohesive framework to
                    develop programming skills. Beyond its role as teaching material, "Sensory Narratives" also reflect
                    his artistic
                    spirit of being oneness with the world.

                    <i><br><br>Since the early day of life, human is at one with nature. Our body senses, reacts, and
                        reflects
                        upon the nature that we are living in constantly. In this nowadays digital landscape, those
                        emotional rapports seems to fade under the shadow of the new virtual technology. Can we mediate
                        the
                        relationship between human and nature via technology? This course investigates the vivid world
                        of
                        signal around us - image, sound, and data; and use them as inspiration and resource for our
                        creative
                        practice.</i>

                    <br><br>Toward the end of this course, students learn to use p5.js to build a cohesive system that
                    observes,
                    documents, and visualizes the changes that are happening in their nature. Students also learn
                    to
                    integrate programming with other creative practices to furthermore manifest their artworks in any
                    new formats.

                    <br><br>The course is built upon 4 units with increasing difficulty:

                    <br><br>‚§∑Unit 1: Connect ‚éØ to play with mouse and keyboard interaction while gaining familiarity
                    with basic
                    Javascript syntax.
                    <br>‚§∑ Unit 2: Transmit Vision ‚éØ to understand the world through images while practicing using
                    arrays and
                    functions.
                    <br>‚§∑ Unit 3: Transmit Sound ‚éØ to make artworks that react to sound while getting to know
                    object-oriented programming, animation, and vector & forces.
                    <br>‚§∑ Unit 4: Transmit Data ‚éØ to control our canvas using external data while learning about API
                    and
                    making our first data-driven application.

                    <hr>
                <div>
                    <h2>Unit 1: Connect</h2>
                    <p>By the end of this unit, we make an interactive letter and send it to our loved ones. In this
                        very
                        intimate format of a letter, we use technology as a bridge to deliver our thoughts and emotion.
                        The
                        letter can be made using material that we learnt in class (shape, color, typography) and
                        elaborated
                        with animation and interaction via mouse and keyboard.
                    </p>

                    <p style="text-align: right;">SAMPLE WORK</p>
                    <div id="portrait-display"></div>
                    <p id="portrait-guide"><i>poem by Ocean V∆∞∆°ng<br>touch to read</i></p>
                    <p><i>
                            <br>the year is 2017,
                            <br>scorching japan's summer
                            <br>i'm with him in the shower
                            <br>sun, everywhere.
                        </i>
                    </p>

                    <p style="text-align: right;">SUGGESTED SYLLABUS</p>
                </div>
                <div style="padding-bottom: 10px;">‚§∑ SESSION 1. First Interaction
                    ‚éØ What is p5.js? Demystifying: code, language, libraries.
                    ‚Ä¢ Make your first p5.js sketch.
                    ‚Ä¢ Function: p5.js built-in function
                    ‚Ä¢ The coordinate system, shape, and colors
                    ‚Ä¢ Variables
                    ‚Ä¢ Simple animation and mouse interaction
                    ‚Ä¢ Tidy Code and Documentation
                </div>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 2. Control
                    ‚éØ map() & lerpColor()
                    ‚Ä¢ if condition to control interaction and animation using
                    ‚Ä¢ Interaction with mouse using mousePressed()
                    ‚Ä¢ Interaction with keyboard using keyPressed()
                    ‚Ä¢ Random
                </div>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 3. Transformation & Iteration
                    ‚éØ Write your own function
                    ‚Ä¢ Transformation: translate(), scale(), rotate()
                    ‚Ä¢ push() and pop()
                    ‚Ä¢ Typography: adding and styling text
                    ‚Ä¢ Iterative: for Loop
                </div>


                <hr>
                <h2>Unit 2: Transmit Vision</h2>
                <p>
                    Upon the connection with computer we have established in Unit 1, we continue to build a more sensory
                    interaction: seeing. Can computer see things as the way human do? In this unit, we learn to apply
                    coding into capture and analysing images. We also learn to program a project on a more professional
                    level, away from pure online editor. For this unit project, students will use camera and other
                    recording devices to capture the essences of where they are living. We incorporate programming to
                    highlight those essences either through manipulating the images' structure or semantics.
                </p>
                <p style="text-align: right;">SAMPLE WORK</p>
                <img src="https://codesurfing.netlify.app/scr/p2-sample-thumb.png">
                <p>
                    <i>All the strangers I met on B·ªù K√™nh Nhi√™u L·ªôc‚Äù, is a reflection of myself living in the
                        overwhelming
                        Saigon, where I ride 12km every day to work. It is a still film with a huge cast trying to get
                        through the screen yet no one is the main character. To make this, I performed object detection
                        on a
                        dashcam driving through Saigon. The model extracted drivers and placed them on the mural.</i>
                </p>

                <p style="text-align: right;">SUGGESTED SYLLABUS</p>
                <div style="padding-bottom: 10px;">‚§∑ SESSION 4. Working with Images
                    ‚éØ Programming in local environment: text editor, CLI, and all things needed.
                    ‚Ä¢ Structure of a p5 project: index.html, style.css, and sketch.js
                    ‚Ä¢ Practice: Making buttons.
                    ‚Ä¢ Working with images
                    ‚Ä¢ Working with videos
                    ‚Ä¢ Control media: play, pause, loop, duration.
                    ‚Ä¢ Practice: Making Zine
                </div>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 5. From Pixel to Image
                    ‚éØ Array and array manipulation
                    ‚Ä¢ Color spaces: RGB and HSL.
                    ‚Ä¢ Canvas as a grid
                    ‚Ä¢ Understanding image as arrays of pixels: updatePixels() and loadPixels().
                    ‚Ä¢ Working with webcam.
                    ‚Ä¢ Practice: ASCII Webcam.
                </div>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 6. More Than Just Pixels
                    ‚éØ Learning images through machine learning.
                    ‚Ä¢ Image classification
                    ‚Ä¢ Object detection
                    ‚Ä¢ Simple machine learning application using ml5.js
                    ‚Ä¢ Debugging & Optimization
                    ‚Ä¢ Using setInterval(), setTimeOut() to schedule function execution.
                </div>
                <hr>
                <h2>Unit 3: Transmit Sound</h2>
                <p>
                    Using code as an instrument to amplify the vivid world around us. In this unit, we learn to
                    visualize sound using programming. We focus on animation and the use of algorithm and vectors on
                    enriching our animation. For this unit project, students go out to their neighborhood and record a
                    soundscape. Then using
                    programming to amplify the subject of the soundscape in visual.
                </p>
                <div>
                    <img src="assets/jump/jump_0.png">
                    <p><i>
                            From 2023 footages in my phone, ‚Äúi let the fish into the ocean‚Äù is a
                            meditative montage on my intimacy with nature ‚éØ water, air, and biological bodies.
                            ‚éØ through the way we flow, intertwine, and harmonize this school of lives together.
                        </i>
                    </p>
                    <p><i><a href="https://symphonious-kleicha-cbc328.netlify.app/" target="_blank">Leave this page for
                                that realm.</a></i></p>
                    <p style="text-align: right;">SUGGESTED SYLLABUS</p>
                    <div style="padding-bottom: 10px;">
                        ‚§∑ SESSION 7. Sound
                        ‚éØ Understanding the concept of sound.
                        ‚Ä¢ The physics of sound: Amplitude, frequency, and FFT
                        ‚Ä¢ Digital format of sound: Different file types and terminologies.
                        ‚Ä¢ Legal resources: Open archives and free-to-access material.
                        ‚Ä¢ Load and control sound in p5.
                        ‚Ä¢ Simple shapes react to sound.
                        ‚Ä¢ Practice: Simple visualization - Sine wave.
                        ‚Ä¢ Practice: Simple visualization - Frequencies in bars.
                        ‚Ä¢ Practice: Spectrogram.
                    </div>
                    <div style="padding-bottom: 10px;">
                        ‚§∑ SESSION 8. Sound Visualization
                        ‚éØ Object-oriented programming: What is it? How to use it?
                        ‚Ä¢ Advanced animation with sin, cos, tan
                        ‚Ä¢ Practice: Animate text with textToPoints() and boundText()
                        ‚Ä¢ Working with microphone.
                        ‚Ä¢ Practice: Sound animated typography.
                        ‚Ä¢ P5LIVE
                    </div>
                    <div style="padding-bottom: 10px;">
                        ‚§∑ SESSION 9. Sound Visualization
                        ‚éØ Acoustics of music.
                        ‚Ä¢ Vectors and Forces: Using physics to enrich animation.
                        ‚Ä¢ Perlin Noise.
                        ‚Ä¢ Practice: Flow Field
                        ‚Ä¢ Git and Deploy
                    </div>
                </div>

                <hr>
                <h2>Unit 4: Transmit Data</h2>
                <p>Human practices require the ability of analyzing signals that we can neither see nor hear. Fishermen
                    relies on currents, winds, and inherited knowledge to navigate. Farmers relies on rain level and
                    temperature to adjust their harvest. This unit will guide students to design a cohesive system from
                    devices and bodies of code to sense and make sense of surrounding data that beyond our seeing and
                    hearing.
                </p>
                <p style="text-align: right;">SAMPLE WORK</p>
                <p><i>to be updated</i></p>
                <p style="text-align: right;">SUGGESTED SYLLABUS</p>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 10. The Data Pipeline
                    ‚éØ Getting to know data and what data can do.
                    ‚Ä¢ Data type: .csv
                    ‚Ä¢ Load table and extract data with getRow, getColumn, getNum, getString.
                    ‚Ä¢ Quick visualization.
                    ‚Ä¢ Connect p5 with Google Sheet
                    ‚Ä¢ Practice: Collect and visualize your own data.
                </div>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 11. The Story of Data
                    ‚éØ Descriptive statistics, measurements of data.
                    ‚Ä¢ Deep dive into data visualization.
                    ‚Ä¢ Chart selection and storytelling in data visualization
                    ‚Ä¢ Data source and ethics in using data.
                    ‚Ä¢ Practice: 50 Ways to Visualize A Data.
                </div>
                <div style="padding-bottom: 10px;">
                    ‚§∑ SESSION 12. Realtime
                    ‚éØ Datatype: JSON
                    ‚Ä¢ Connect p5 with Data API
                    ‚Ä¢ Real-time visualization
                    ‚Ä¢ Deploy
                    ‚Ä¢ Beyond data: Machine learning
                    ‚Ä¢ Predicting with Linear Regression
                </div>

                <hr>
                <p>
                    <img src="/assets/sensory-narratives/vinhhy.jpg">
                    <br><br><i>I dedicate this curriculum as an artistic tribute to my homeland - Southern Coast of
                        Vietnam.
                        It teaches me how to become a human and how to always look back into what nature and what my
                        ancestors have always
                        been giving me.

                        <br><br>Years passed by but I am still that little boy who walked barefoot on the beach
                        collecting seashells for his
                        school project. I hope more of us would go back to that precious lessons from the nature.

                        <br><br>Here's to my beautiful land.
                        <br>Here's to all the teachers on my beautiful land.
                    </i>
                </p>


            </section>

            <section id="beach-pocket">
                <h2>
                    (2022) Beach Pocket
                </h2>
                <div class="tag-container">
                    <span class='tag'>photo</span>
                    <span class='tag'>print</span>
                </div>
                <div>
                    <br>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/4.png"><img src="assets/beach-pocket/4.png"
                            style="width:60%"></a>
                    <br>
                    <p>
                        First thing I said when a guy took my shirt off was always ‚éØ ‚ÄúAm I too skinny?‚Äù
                    </p>
                    <p>
                        From 2019 to 2022, my best friends and I made occasional getaways to the beaches in Vietnam.
                        There we swam, sunbathed, read, danced, and radiated under the sun. There I found comfort in my
                        own skin. There I realized the beauty of our shapes. The whole process is a healing journey for
                        me.
                    </p>
                    <p>
                        This pocket notebook includes all the portraits and self-portraits that I documented during the
                        time.
                    </p>

                    <a data-fslightbox="gallery" href="assets/beach-pocket/1.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/1.png"></a>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/5.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/5.png"></a>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/2.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/2.png"></a>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/6.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/6.png"></a>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/7.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/7.png"></a>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/8.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/8.png"></a>
                    <a data-fslightbox="gallery" href="assets/beach-pocket/3.png"><img class="beach-pocket-img"
                            src="assets/beach-pocket/3.png"></a>

                    <p>
                        <br>‚ÄúMy boyfriend once said that I was so tiny
                        <br>That he could carry me in his pocket anywhere
                        <br>So put me in your pocket
                        <br>Use me as your time goes by
                        <br>Use my body as your late-night canvas

                        <br>Write on me
                        <br>Compose on me
                        <br>Fast on me
                        <br>Slow on me
                        <br>Release on me
                        <br>Spit on me
                        <br>Piss on me
                        <br>Bleed on me‚Äù


                        <br><br>‚ú£Ôºä‚ú£

                        <br>Produced by <a href="https://wedogood.party" target="_blank" class="link-out">wedogood</a>.
                        <br>64 pages on risograph using aqua, yellow, flourescent pink.
                    </p>
                </div>
            </section>

            <section id="gai-gia">
                <h2>
                    (2022) „Ç¨„Ç§„Ç∏„É£Âà•Â∫ú
                </h2>
                <div class="tag-container">
                    <span class='tag'>photo</span>
                    <span class='tag'>print</span>
                </div>
                <div>
                    <img style="width:70%" src="assets/gai-gia/gaigiabeppu_zine01 copy.png">

                    <br>
                    <p>
                        Every year when the cicadas start to sing, I miss Japan dearly, as if a part of myself had been
                        buried under the Minami Ishigaki park, where we hung out by the swings, singing, and smoking.
                    </p>

                    <p>
                        This summer, as the cicadas are singing again, I invited Cao Mieu to join me in a conversation
                        about our Japanese memoirs. But instead of texts, we would reply to each other with artworks.
                        Every page is a response to the previous. All communication takes place only within these pages.
                    </p>

                    <p>
                        I lost my residence card years ago. Mieu still has hers, so she will hereby board the page
                        first.
                    </p>


                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine01.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine01.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine02.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine02.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine03.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine03.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine04.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine04.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine05.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine05.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine06.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine06.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine061.png"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine061.png"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine07.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine07.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine08.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine08.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine09.jpeg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine09.jpeg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine10.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine10.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine11.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine11.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine12.jpg"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine12.jpg"></a>
                    <a data-fslightbox="gallery" href="assets/gai-gia/gaigiabeppu_zine13.png"><img style="width:70%"
                            src="assets/gai-gia/gaigiabeppu_zine13.png"></a>

                </div>
            </section>

            <section id="live-laugh-dick">
                <h2>
                    (2022) Live. Laugh. Dick(s).
                </h2>

                <div class="tag-container">
                    <span class='tag'>Python</span>
                    <span class='tag'>print</span>
                </div>

                <div>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/1.png"><img
                            src="assets/live-laugh-dicks/1.png"></a>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/2.png"><img
                            src="assets/live-laugh-dicks/2.png"></a>
                    <p>
                        Back in April, wedogood invited me to join their zine with the theme of ‚ÄúLove Machine. Machine
                        Love‚Äù. And all I brought was erotism, fantasy, and re-imagination. This poster is a stand-alone
                        version of my work in the zine. More than a collection of quirky-looking toys, It reflects our
                        current perception of sex toy design (dildos and butt plugs in particular) while suggesting new
                        boundaries for toy design.
                    </p>

                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/3.png"><img
                            src="assets/live-laugh-dicks/3.png"></a>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/4.png"><img
                            src="assets/live-laugh-dicks/4.png"></a>

                    <p>
                        After being trained with 3000 photos of toys, the generative model clearly gets the idea that a
                        sex toy needs to be pointed (of course). But it takes the idea further by re-imagining toys with
                        multiple heads, and toys with irregular shapes or shapes that are different from cylinders.
                        Several generated samples also include toys that are bound together since e-commerce often
                        places their toys next to each other in product photos. If such an arrangement stimulates the
                        buyer, then why not include them in the real product design? Many of the generated samples also
                        propose getting rid of the inside of the toys as it is not a significant feature. They suggest
                        void, disjoint parts, transparent material, and anything else but the common solid shape.

                        Pleasure has its own curiosity. And maybe toys for pleasure should also be more suggestive,
                        rather than adaptive.

                    </p>
                    <p>

                        This project is built on my custom GAN model, inspired by StyleGAN2. The StyleGAN2 architecture
                        itself is gigantic. To afford training, I made multiple adjustments in the architecture,
                        including downsizing the output image size to 128x128. This seriously damaged the print quality
                        but Risograph helped me bypass that. I also divided the training into multiple sessions + used
                        the Tensorflow Data Dataset & Tensorflow Record to optimize the whole training speed. All are
                        for this project to be run on the free resource of Google Colab, which has a limited quota every
                        day. So much engineering just to have more dicks while paying less ü•¥

                    </p>


                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/6.gif"><img
                            src="assets/live-laugh-dicks/6.gif"></a>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/7.png"><img
                            src="assets/live-laugh-dicks/7.png"></a>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/8.gif"><img
                            src="assets/live-laugh-dicks/8.gif"></a>

                    <p>
                        <br>WHY RISOGRAPH?

                        <br><br>Generative art is not for size queen. Artworks generated from ML model struggle to have
                        a good
                        resolution. A simple image of 300x300 would take 90,000 units when being flattened. It means
                        that a larger output images come with a larger cost of computation. It often requires days of
                        training on expensive GPU. When it comes to printing, this limit in output results in pixelating
                        details, blurry edges, and inconsistent separation between object and background. Not only that,
                        generative images oftentimes have the checkerboard effect, as a result that the machine
                        ‚Äúpainted‚Äù each pixel independently and lack of perception of the image as a whole.

                    </p>
                    <p>
                        In order to produce this digital artwork in high-quality print (A3), we first put the 128x128
                        generated images through a half-toned treatment - a technique to simulate the image tone through
                        dots. By carefully adjusting the dot size, we gave the pixelated images a sharper optic illusion
                        in general. A subtly similar pair of aqua ink and purple paper were then chosen to let the
                        half-toned dots blend smoothly with the background. The various size of dots + different % of
                        ink embrace the blurry edge. The aqua ink also expands optically when we tilt the poster to
                        different light direction. Object edges ‚Äúfade‚Äù gradually into paper like chalk. The drawback of
                        pixelating and not having sharp edges is now a compliment toward the initial inspiration of
                        stains.
                    </p>

                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/9.png"><img
                            src="assets/live-laugh-dicks/9.png"></a>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/10.png"><img
                            src="assets/live-laugh-dicks/10.png"></a>

                    <p>
                        Crossing between multiple forms ‚éØ from photographs, to numbers, to logic, to a new form of
                        photographs, then comes alive as a print. A journey from modern computation to a long-lived
                        printing technique; from abstract to physical, with which we can see, can touch, and can
                        interact.

                        I think it is beautiful.
                    </p>

                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/11.png"><img
                            src="assets/live-laugh-dicks/11.png"></a>
                    <a data-fslightbox="gallery" href="assets/live-laugh-dicks/12.png"><img
                            src="assets/live-laugh-dicks/12.png"></a>
                    <p><i>background: IG/manual_singularity</i></p>

                </div>
            </section>

            <section id="wes-anderson">
                <div>
                    <h2>
                        (2021) Watching Wes Anderson Without Watching Wes Anderson
                    </h2>

                    <div class="tag-container">
                        <span class='tag'>Python</span>
                        <span class='tag'>data analysis</span>
                    </div>

                    <a data-fslightbox="gallery" href="assets/wes-anderson/aqua_1.png"><img
                            src="assets/wes-anderson/aqua_1.png"></a>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/dog_1.png"><img
                            src="assets/wes-anderson/dog_1.png"></a>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/hotel_1.png"><img
                            src="assets/wes-anderson/hotel_1.png"></a>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/moon_1.png"><img
                            src="assets/wes-anderson/moon_1.png"></a>

                    <p class="pt-2">
                        In 2021, Saigon went dormant under COVID lockdown. No one can set foot beyond their door. So did
                        I
                        and my housemate. We ended up doing a marathon of Wes Anderson movies. Going through all his
                        movies
                        was like walking on a train, that moving so fast, that all the beautiful scenes become color
                        running
                        across my window. Color is the main actor in his movies.
                    </p>
                    <p>
                        The normal way to watch a movie requires audiences to sit through frame by frame. A movie
                        presents
                        itself linearly with time with visual elements built up on top of each other. This project
                        challenges that concept and aims to understand the visual landscape of Wes Anderson movies
                        through
                        just one single look.
                    </p>
                    <p>
                        To achieve that, each frame of the film was flattened from a rectangular shape (720x1280) to
                        into a
                        long strip (1x921,600). Then, all the strips were stacked on top of each other to create the
                        final
                        artwork. As a result, vertically, from top to bottom, we are ‚Äúwatching‚Äù the movie from the
                        beginning
                        to the end. Horizontally, from left to right, our eyes are moving zig-zag in one scene of the
                        movie
                        (left to right, top to bottom).
                    </p>
                    <p>
                        In the end, this project reveals how Wes Anderson uses colors to create the world surrounding
                        his
                        characters, and how that colorful world flows according to his characters' emotion.
                    </p>
                    <h3>
                        1/ The Life Aquatic with Steve Zissou (2004)
                    </h3>

                    <a data-fslightbox="gallery" href="assets/wes-anderson/aqua_1.png"><img
                            src="assets/wes-anderson/aqua_1.png"></a>

                    <p>
                        One of the first Wes Anderson‚Äôs, dated back in 2004. The movie's color is everything but its
                        name ‚Äúaqua‚Äù. Most of the scenes are in a warm, earthy tone while the color aqua is used as
                        highlights scattered throughout the movie.</p>

                    <p>When looking closer, I found out that aqua was used specifically as a way to revert the movie's
                        emotion - from the scene where Steve met his wife, to the pirates‚Äô raid, and to his son‚Äôs last
                        moment. The color aqua sets the boundary of bright sunshine and dark ocean, surface and below,
                        inward and outward, carefree voyage life and emotional tension. It makes the peak and valley in
                        Steve Zissou‚Äôs life.
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/aqua_3.png"><img
                            src="assets/wes-anderson/aqua_3.png"></a>
                    <h3>
                        2/ Moonrise Kingdom (2012)
                    </h3>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/moon_1.png"><img
                            src="assets/wes-anderson/moon_1.png"></a>
                    <p>
                        Moonrise Kingdom is divided into two distinctive palettes: before the storm and after the storm.
                        The ‚Äúbefore the storm‚Äù embraces the warm colors of yellow, green, and brown, with scenes mostly
                        shot in bright sunlight while the ‚Äúafter the storm‚Äù rages in cooler shades of blue and teal,
                        with lots of scenes without the sun or even in the dark.
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/moon_2.png"><img
                            src="assets/wes-anderson/moon_2.png"></a>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/moon_3.png"><img
                            src="assets/wes-anderson/moon_3.png"></a>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/moon_4.png"><img
                            src="assets/wes-anderson/moon_4.png"></a>
                    <p>
                        The transition from the bright color to the darker one doesn‚Äôt follow the change of nature (the
                        arrival of the storm) in the movie. It, however, follows the transition of the characters‚Äô
                        emotions. The change started right after Sam and Suzy got caught by the beach. The following
                        scene of Suzy‚Äôs conversation with her mom immediately takes the sunlight out and drowns the
                        movie in the cold tub. Perhaps, the movie‚Äôs real storm already raged after that conversation.
                    </p>

                    <a data-fslightbox="gallery" href="assets/wes-anderson/moon_6.png"><img
                            src="assets/wes-anderson/moon_6.png"></a>

                    <h3>
                        3/ The Grand Budapest Hotel (2014)
                    </h3>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/hotel_1.png"><img
                            src="assets/wes-anderson/hotel_1.png"></a>

                    <p>
                        The movie has many noticeable black columns that run vertically. Their widths vary in the
                        beginning, then become consistent as the movie goes on. These black columns are created from the
                        black margin of the frames. Different size of black margin signifies different screen ratios. In
                        fact, Wes Anderson intentionally used different screen ratios to mimic different eras‚Äô cinematic
                        styles. The 80‚Äôs ‚éØ 1.85 : 1, The 60‚Äôs ‚éØ 2.40 : 1, The 30‚Äôs ‚éØ 1.37:1.
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/hotel_2.png"><img
                            src="assets/wes-anderson/hotel_2.png"></a>
                    <p>
                        The movie is clearly divided into blocks of colors. Each group of scenes is in one distinctive
                        palette of color. The transition of color is both more extreme and playful than in his early
                        works - Moonrise Kingdom and The Life Aquatic of Steve Zissou.
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/hotel_3.png"><img
                            src="assets/wes-anderson/hotel_3.png"></a>

                    <h3>
                        4/ Isle of Dogs (2018)
                    </h3>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/dog_1.png"><img
                            src="assets/wes-anderson/dog_1.png"></a>
                    <p>
                        Continued with the idea of using colors to define space for characters‚Äô emotions, Isle of Dogs
                        used extreme colors, black and white, to depict two different groups of scenes: the trash island
                        and the city hall. Yellow strips that run horizontally between them are Tracy Walker. She brings
                        light to the revolution of Atari and the dogs.
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/dog_2.png"><img
                            src="assets/wes-anderson/dog_2.png"></a>
                    <p>
                        Several groups of scenes in Isle of Dogs maintain a fixed layout, with both characters and the
                        camera making minimal moves. For example, in the white strip area in the middle, we can see that
                        the black area (the characters) stays in place for several continuous scenes. This can be the
                        effect of stop motion, where continuous scenes have very subtle changes, so the audiences can
                        really focus on such change and the ‚Äústop-motion delay‚Äù between the change. For example, the
                        making sushi scene.

                        However, when considering other movies by Wes Anderson, The Grand Budapest Hotel also has this
                        same pattern. Many scenes in the movie, especially scenes where characters discuss, have very
                        minimal camera movement. So rather than highlighting the effect of stop motion, in these scenes
                        of Isle of Dog, Wes Anderson is leveraging stop motion to achieve his own distinctive technique.
                        They play out so well and compliment each other.
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/dog_3.png"><img
                            src="assets/wes-anderson/dog_3.png"></a>
                    <p>
                        <i>Isle of Dogs</i>
                    </p>
                    <a data-fslightbox="gallery" href="assets/wes-anderson/dog_4.png"><img
                            src="assets/wes-anderson/dog_4.png"></a>
                    <p>
                        <i>The Grand Budapest Hotel</i>
                    </p>

                    <hr>
                    <p><i>Inspiration</i></p>
                    <img src="assets/wes-anderson/raucau.jpeg">
                </div>
            </section>

            <section id="esrgan">
                <h2>
                    (2020) Enhanced Super Resolution GAN on Tensorflow 2
                </h2>
                <div class="tag-container">
                    <span class='tag'>Python</span>
                    <span class='tag'>machine learning</span>
                </div>
                <div>
                    <a data-fslightbox="gallery" href="assets/esrgan/1.jpeg"><img src="assets/esrgan/1.jpeg"></a>
                    <p>
                        VISION2020 aims at recovering a high resolution image from a low resolution one. The project is
                        based largely on the excellent research of Xintao Wang, et al. on ESRGAN (2018) and their
                        implementation using Pytorch. Inspired from the research, my version of ESRGAN is optimized and
                        built entirely on Tensorflow 2.0. It successfully resizes the image up to x64 on square area.
                    </p>
                    <p>
                        Single image super-resolution (SISR), as a fundamental low-level vision problem, has attracted
                        increasing attention in the research community and AI companies. SISR aims at recovering a
                        high-resolution (HR) image from a single low-resolution (LR) one. Since the pioneer work of
                        SRCNN
                        proposed by Dong et al., deep convolution neural network (CNN) approaches have brought
                        prosperous
                        development. Various network architecture designs and training strategies have continuously
                        improved
                        the SR performance.
                    </p>
                    <p>

                        The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of
                        generating realistic textures during single image super-resolution. However, the hallucinated
                        details are often accompanied with unpleasant artifacts. To further enhance the visual quality,
                        we
                        thoroughly study three key components of SRGAN - network architecture, adversarial loss and
                        perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN).
                    </p>
                    <p>
                        In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch
                        normalization
                        as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let
                        the
                        discriminator predict relative realness instead of the absolute value. Finally, we improve the
                        perceptual loss by using the features before activation, which could provide stronger
                        supervision
                        for brightness consistency and texture recovery. Benefiting from these improvements, the
                        proposed
                        ESRGAN achieves consistently better visual quality with more realistic and natural textures than
                        SRGAN.
                    </p>

                    <a data-fslightbox="gallery" href="assets/esrgan/2.png"><img src="assets/esrgan/2.png"></a>

                    <p>
                        fig1 ‚éØ (x4 per dimension) generated image successfully retains small detail like the strip at
                        the shoulder area and the human head.
                    </p>
                    <a data-fslightbox="gallery" href="assets/esrgan/3.png"><img src="assets/esrgan/3.png"></a>
                    <p>
                        fig2 ‚éØ (x4 per dimension) Natural features like eyes are well reconstructed.
                    </p>
                    <a data-fslightbox="gallery" href="assets/esrgan/4.png"><img src="assets/esrgan/4.png"></a>
                    <p>
                        fig3 ‚éØ (x8 per dimension) Double challenging, then model successfully reconstruct pattern and
                        lines.
                    </p>
                    <a data-fslightbox="gallery" href="assets/esrgan/5.png"><img src="assets/esrgan/5.png"></a>
                    <p>
                        fig4 ‚éØ (x8 dimension) Letters are brought back to vision.
                    </p>

                    <p>
                        Full project code is available on <a href="https://github.com/nhanphan0411/VISION2020"
                            class="link-out" target="blank_">Github</a>
                    </p>

                </div>
            </section>

            <section id="viet-ocr">
                <h2>
                    (2020) Vietnamese Handwritten Optical Character Recogition
                </h2>
                <div class="tag-container">
                    <span class='tag'>Python</span>
                    <span class='tag'>machine learning</span>
                </div>
                <div>
                    <p>
                        Optical Character Recognition is one active field that bridges between computer vision and
                        natural language processing. As much as the field emerges within machine learning community, it
                        still performs poorly on local language, including Vietnamese with our distinctive symbol (·ªÖ, ·∫©,
                        ·ª© for example). The lack of data is one of the main reason behind it. In 2018, Cinnamon AI aimed
                        to solve that challange by hosting a hackathon with a Vietnamese handwritten dataset. It
                        includes all the address written in Vietnamese. The model can be immediately apply in post
                        service to alleviate the need of manual input.
                    </p>
                    <p>
                        All code of this project can be found on my <a href="https://github.com/nhanphan0411/viet-ocr"
                            class="link-out" target="blank_">Github üëæ</a>
                    </p>

                    <a data-fslightbox="gallery" href="assets/ocr/1.png"><img src="assets/ocr/1.png"></a>

                    <p>
                        ‚ùä RESULT ‚ùä

                        My project successfully achieved
                        Character Error Rate: 0.04
                        Word Error Rate: 0.14
                        Sentence Error Rate: 0.82
                    </p>
                    <p>
                        The hackathon's winner score is 0.1x on the Word Error Rate.
                        Other metric results were not disclosed.
                    </p>
                    <p>
                        ‚ùä SAMPLE PREDICTIONS ‚ùä
                        T = True Label
                        P = Prediction
                    </p>
                    <a data-fslightbox="gallery" href="assets/ocr/2.png"><img src="assets/ocr/2.png"></a>
                    <p>
                        ‚ùä IMAGE PREPROCESS ‚ùä
                        The preprocess was built mainly on OpenCV with 3 phases
                        1/ Thresholding
                        2/ Resize to 128x1024
                        3/ Remove Recursive (reference to A. Vinciarelli and J. Luettin)

                        (Before - After)
                    </p>
                    <a data-fslightbox="gallery" href="assets/ocr/3.png"><img src="assets/ocr/3.png"></a>
                    <a data-fslightbox="gallery" href="assets/ocr/4.png"><img src="assets/ocr/4.png"></a>
                    <p>
                        ‚ùä MODEL ‚ùä
                        CRNN + CTC Loss is used to solve this challenge.
                        CNN blocks with skip connections (inspired by ResNet50) are used to extract the features from
                        the input image.
                        The extracted feature map will be then passed through the LSTM layers.
                    </p>
                    <a data-fslightbox="gallery" href="assets/ocr/5.png"><img src="assets/ocr/5.png"></a>
                    <br>
                    <p>Training Log</p>
                    <a data-fslightbox="gallery" href="assets/ocr/6.png"><img src="assets/ocr/6.png"></a>
                </div>
            </section>

            <section id="amazon">
                <h2>
                    (2019) Understand The Amazon From Above
                </h2>
                <div class="tag-container">
                    <span class='tag'>Python</span>
                    <span class='tag'>machine learning</span>
                </div>
                <div>
                    <img src="assets/amazon/1.jpg">

                    <p><i>This project is an entry of the corresponding <a
                                href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data"
                                class="link-out">Kaggle competition.</a></i></p>

                    <p>
                        Every minute, the world loses an area of forest the size of 48 football fields. And
                        deforestation in the Amazon Basin accounts for the largest share, contributing to reduced
                        biodiversity, habitat loss, climate change, and other devastating effects. But better data about
                        the location of deforestation and human encroachment on forests can help governments and local
                        stakeholders respond more quickly and effectively.
                    </p>

                    <p>
                        This analysis uses Deep Learning to classify the spatial images of the Amazon forest taken by
                        the satellite. From that, it hopes to shed a light on understanding how the forest has change
                        naturally and manually. Thus, help preventing deforestation.
                    </p>

                    <img src="assets/amazon/2.png">
                    <br>
                    <p>
                        The project is built on dataset from the Kaggle competition in 2016. It contains more than
                        40.000 images, taken by Planet using sattelites.
                    </p>
                    <p>
                        Planet, designer and builder of the world‚Äôs largest constellation of Earth-imaging satellites,
                        will soon be collecting daily imagery of the entire land surface of the earth at 3-5 meter
                        resolution. While considerable research has been devoted to tracking changes in forests, it
                        typically depends on coarse-resolution imagery from Landsat (30 meter pixels) or MODIS (250
                        meter pixels). This limits its effectiveness in areas where small-scale deforestation or forest
                        degradation dominate.
                    </p>

                    <h3>Result</h3>
                    <p>
                        The project successfully got the score of 0.90 on the official test set.
                    </p>
                    <img src="assets/amazon/3.png">
                    <img src="assets/amazon/4.png">

                    <h3>Challenge</h3>
                    <p>1Ô∏è/ Multi-label: Each image is labeled with multiple tags (at least 2, at max 9). The tags fall
                        into
                        17 categories, which are the forest landscape types. Since the tags in each label are mutually
                        exclusive, they are treated as multiple binary classification problems. Thus, binary
                        cross-entropy
                        are chosen to be the loss function.
                    </p>

                    <p>
                        2Ô∏è/ Imbalance: The dataset is severely imbalance with tags like Primary or Agriculture appear in
                        90%
                        of the dataset. While other tags like Blooming or Conventional Mine can only be seen in less
                        than
                        500 observations (even less than 100 for Burn Down).
                    </p>
                    <p>
                        In the first base-line experiment, the model was totally bias toward the major tags. It predicts
                        the
                        major tags to appear in every data and almost never made a prediction with the minor tags.
                        To tackle the problem of imbalance dataset, evaluation metrics must be chosen carefully. F2 is
                        chosen to be the main metrics to evaluate the training. It watches over the harmonic mean
                        between
                        the Precision and Recall while favors Recall specifically. In other word, it is the attempt to
                        reduce the number of False Negative, where the model fails to identify the absence of a tag.
                    </p>
                    <p>
                        3Ô∏è/ Optimization: 400.000 images, a CNN model, and Google Colab's limited resource do not seem
                        to
                        mix well together. The training was slow at first and interupted often. Several improvements,
                        mostly
                        on the Tensorflow pipeline, were conducted to speed up the training:
                        Using TFRecord to convert the raw images into byte-like data to reduce the amount of time
                        spending
                        on reading data from their paths.
                    </p>
                    <p>
                        Using tf.data.Dataset with shuffle, map, batch, prefetch to optimize the reading data process by
                        redistributing the tasks for agents to work concurrently, thus, avoid bottleneck. An attempt to
                        use
                        cache was also made but failed due to the limited RAM.
                    </p>
                    <p>
                        Processing image with Tensorflow: The dataset contains images in JPG - RGBA. The built-in decode
                        function tf.io.decode_jpeg only works on 1 or 3-channel image. Attempt on encoding a JPG RGBA
                        image
                        returns black black and black. We need a tensorflow encoding function to work in this part
                        because
                        the pipeline is built entirely on Tensor for the optimization purpose.
                        To tackle the problem, the raw images were first read by Matplotlib then converted into
                        byte-like
                        and wrote into TFRecords. When reading the data from TF Record, instead of using the built-in
                        decode
                        image function, we use tf.io.parse_tensor following with reshaping.
                    </p>
                    <h3>Sample Prediction</h3>
                    <a data-fslightbox="gallery" href="assets/amazon/5.png"><img src="assets/amazon/5.png"></a>
                    <p>Full code of this project can be visited at <a
                            href="https://colab.research.google.com/drive/1s8iFtj7D4D0BNlsR7P9hvfzsqV8XhjTD?authuser=1"
                            class="link-out" target="blank_">Google Colaboratory</a>üëå</p>
                </div>
            </section>

            <!-- <section id="further">
                <h2>
                    <a href="before2020.html" style="text-decoration:none!important; color:rgb(148, 58, 233)">Before
                        2020 ‚Üí</a>
                </h2>
            </section> -->
        </div>
    </div>
</body>

<script src="assets/portrait/sketch.js"></script>
<script src="fslightbox.js"></script>

<script>

    jQuery(document).ready(function ($) {
        $(".clickable-row").click(function () {
            window.open($(this).data("href"), '_blank');
        });
    });

    // document.body.onscroll = function(){
    // document.body.style.backgroundPositionX = window.pageXOffset +"px";
    // };

</script>

</html>