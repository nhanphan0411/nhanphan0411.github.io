<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NQ304D3RY1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-NQ304D3RY1');
    </script>
    <title>Nhan Phan</title>
    <meta charset="utf-8">
    <meta name="description" content="Nhan Phan">
    <meta name="author" content="Nhan Phan">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="refresh" content="600">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;0,700;1,400;1,600;1,700&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="style_2.css">
    <!-- <link rel="stylesheet" type="text/css" href="style_small.css"> -->

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">

    <link href="https://vjs.zencdn.net/8.16.1/video-js.css" rel="stylesheet" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="//toolness.github.io/p5.js-widget/p5-widget.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/addons/p5.sound.min.js"></script>


</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPJHJ1TMV0"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-ZPJHJ1TMV0');
</script>

<body>
    <div class="row d-flex flex-column flex-sm-row">
        <div class="col-sm-3 d-flex justify-content-between" id="profile">
            <div>
                <div class="nav-header">
                    <h1><i>Nhân Phan</i></h1>
                </div>
                <div>
                    <p>
                        Nhân Phan is a technologist and educator. His artistic practice explores poetic computation
                        in the interplay of programming and other mediums ⎯ including photography,
                        letters, and prints. Taken root from family values and East Asian / Viet heritage, his works
                        journal the life he has lived while mirroring his thoughts on self-identity, beliefs,
                        and romance.
                    </p>
                    <p>
                        Nhân’s works have been featured in Ho Chi Minh City, New York, Bangkok, and Kuala Lumpur. Nhân
                        is the founder of <a href="https://codesurfing.club">CodeSurfing</a>, a science school for
                        artists in Vietnam. He is a mentor of
                        <a href="https://processingfoundation.org/fellowships/fellowships-2023">Processing
                            Fellowship</a> 2024, and also a fellow of the program in
                        2023.
                    </p>

                    <p>
                        Gmail @ <a href="mailto:nhaninsummer@gmail.com">nhaninsummer</a>
                        <br>IG @ <a href="https://instagram.com/nhaninsummer">nhaninsummer</a>
                    </p>
                </div>
            </div>
            <div style="position:fixed; bottom: 0rem;" id="fountain">
                <p style="font-size:100px;">⛲️</p>
            </div>

        </div>
        <div class="col-sm-9" id="work">
            <section class="py-2 mb-2">
                <h2><i>⎯ Selected Works</i></h2>
                <div class="accordion px-sm-4 px-0" id="project">
                    <!-- <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#wa-ceremony" aria-expanded="false"
                                aria-controls="wa-ceremony">
                                <div class="col-sm-8 col-7">
                                    <h4>(2024) 和 ⎯ Ceremony</i></h4>
                                    <span class="tag">p5.js, print</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/wa/1.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="wa-ceremony" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <div class="row">
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/1.png"><img
                                            src="assets/wa/1.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/0.png"><img
                                            src="assets/wa/0.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/2.png"><img
                                            src="assets/wa/2.png" width="100%"></a>
                                </div>

                            </div>
                        </div>
                    </div> -->

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#erase" aria-expanded="false"
                                aria-controls="erase">
                                <div class="col-sm-8 col-7">
                                    <h4>(2024) Erase.</i></h4>
                                    <span class="tag">generative</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/erase/thumb.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="erase" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <div class="row">
                                    <a class="col-sm-6 col-12 p-2" data-fslightbox="wa" href="assets/erase/1.webp"><img
                                            src="assets/erase/1.webp" width="100%"></a>
                                    <div class="col-sm-6 col-12 p-2">
                                        <p class="text-end">
                                            Two agents. <br>Everyday, one wakes up and writes a love poem. <br>Six hours
                                            later, the other wakes up, erases the memory.
                                        </p>
                                        <hr>
                                        <p class="text-end">
                                            <i>
                                                Love letters are generated with OpenAI API, re-trained on artist's
                                                personal conversations of his past relationship.
                                                /// The rate of forgeting (number of characters to be deleted everyday)
                                                is based on Ebbinghaus Forgetting Curve, a mathematical model that
                                                describes how quickly people forget information over time.
                                            </i>
                                        </p>
                                    </div>
                                    <div class="d-flex flex-column">
                                        <a class="col-sm-12 col-12 p-2 pb-sm-1 mb-1" data-fslightbox="erase"
                                            href="assets/erase/4.jpg"><img src="assets/erase/4.jpg"
                                                width="100%"></a>
                                        <a class="col-sm-12 col-12 p-2 pb-sm-1 mb-1" data-fslightbox="erase"
                                            href="assets/erase/1.jpg"><img src="assets/erase/1.jpg" width="100%"></a>
                                        <a class="col-sm-12 col-12 p-2 pb-sm-1 mb-1" data-fslightbox="erase"
                                            href="assets/erase/2.jpg"><img src="assets/erase/2.jpg" width="100%"></a>
                                        
                                    </div>
                                </div>

                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#bat-nang" aria-expanded="false"
                                aria-controls="bat-nang">
                                <div class="col-sm-8 col-7">
                                    <h4>(2024) để quá khứ (sẽ tiếp diễn)</h4>
                                    <span class="tag">p5.js</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/bat-nang/6.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="bat-nang" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p class="text-end" style="margin-bottom:0 !important"> Fellow artist: thou </p>
                                <p class="text-end" style="margin-bottom:0 !important"> Technologist: Nhân Phan</p>
                                <p class="text-end" style="margin-bottom:0 !important"> Research advisor: Yui Nguyễn
                                </p>
                                <p class="text-end"> Technical support: Khôi Nguyễn </p>

                                <p style="margin-bottom:0 !important"> để quá khứ sẽ (tiếp diễn) (loosely translated:
                                    for the past will (continue)) delves into the layered intersections of memory,
                                    language, and urban landscapes. Through an autogenerated poetry mechanism, shadows
                                    of trees cast on walls by sunlight serve as a metaphor for the way the past unfolds
                                    and lingers in the present. This work is a manifestation of tree’s “freedom of
                                    speech’; it allows the trees to</p>
                                <p style="margin-bottom:0 !important">utter the things they cannot talk, about the tree
                                    lines that had fallen, for</p>
                                <p style="margin-bottom:0 !important">the bridges and pillars to come, about</p>
                                <p style="margin-bottom:0 !important">the scorching misery that bestowed, upon</p>
                                <p style="margin-bottom:0 !important">the denuded solitude that casted its shadow, over
                                </p>
                                <p style="margin-bottom:0 !important">the trees enlisted to be chopped, off</p>
                                <p style="margin-bottom:0 !important">the promises to re-plant, at</p>
                                <p style="margin-bottom:0 !important">the promises that decaying on paper, about</p>
                                <p>the continuation of the past continuous.</p>

                                <div class="d-flex justify-content-center py-2">
                                    <iframe title="vimeo-player" class="justify-content-center"
                                        src="https://player.vimeo.com/video/1039610864?h=29329b9140" width="640"
                                        height="360" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p><br>Drawing from over 50 news articles about Metro Line No. 2, the artist selects 49
                                    key
                                    words and phrases, constructing a lexicon of the trees. These words are inserted
                                    into a repetitive syntax—"để...sẽ...để...sẽ..." (to…[we] will…to…will) —that loops
                                    endlessly, pushing language to its breaking point, where meaning dissolves into
                                    oblivion and promises become empty shells. The work is a poetic confrontation
                                    between technology and nature, randomness and
                                    structure, where sunlit shadows evoke the violent history of urban deforestation. It
                                    highlights the tension between the natural world and the relentless forward march of
                                    urbanization, exposing the fragility of both memory and language in the process.</p>

                                <div class="row">
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="bat-nang" href="assets/bat-nang/7.png"><img
                                                src="assets/bat-nang/7.png" width="100%"></a>
                                        <p class="text-center"><i>
                                                Article headlines about the project of Metro 2.
                                            </i></p>
                                    </div>
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="bat-nang" href="assets/bat-nang/8.png"><img
                                                src="assets/bat-nang/8.png" width="100%"></a>
                                        <p class="text-center"><i>
                                                Keywords are randomized into a grid.
                                            </i></p>
                                    </div>
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="bat-nang" href="assets/bat-nang/6.png"><img
                                                src="assets/bat-nang/6.png" width="100%"></a>
                                        <p class="text-center"><i>
                                                Generated poems in the syntax "để...sẽ...để...sẽ..."
                                            </i></p>
                                    </div>
                                </div>

                                <div class="row">
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="bat-nang" href="assets/bat-nang/3.jpg"><img
                                                src="assets/bat-nang/3.jpg" width="100%"></a>
                                        <p class="text-center"><i>
                                                thou explained the project to the audiences at 3nam Studio.
                                            </i></p>
                                    </div>
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="bat-nang" href="assets/bat-nang/2.jpg"><img
                                                src="assets/bat-nang/2.jpg" width="100%"></a>
                                        <p class="text-center"><i>
                                                Marks of sun spot for performance at 3nam Studio (09/2024).
                                            </i></p>
                                    </div>
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="bat-nang" href="assets/bat-nang/5.jpg"><img
                                                src="assets/bat-nang/5.jpg" width="100%"></a>
                                        <p class="text-center"><i>
                                                Audiences observed the poems at 3nam Studio (09/2024).
                                            </i></p>
                                    </div>

                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#keyboard" aria-expanded="false"
                                aria-controls="keyboard">
                                <div class="col-sm-8 col-7">
                                    <h4>(2024) Viet Syllable Keyboard</h4>
                                    <span class="tag">Python, p5.js</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/attv/thumb.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="keyboard" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p class="text-center">Go to app ⎯ <a
                                        href="https://tiengviet.netlify.app/">https://tiengviet.netlify.app/</a></p>
                                <div class="row">
                                    <a data-fslightbox="wa" href="assets/keyboard/2.webp"><img
                                            src="assets/keyboard/2.webp" class="mx-auto d-block" id="keyboard-demo"></a>
                                    <!-- <p class="text-center"><i>
                                            Keyboard in use.
                                        </i></p> -->
                                </div>
                                <!-- <div class="row">
                                    <div class="col-sm-4"></div>
                                    <div class="col-sm-4">
                                        <p>“Between the mountain ridges and sea strands, bridging two major cultures of
                                            India and China, and survived the occupations of three powers: France, USA,
                                            and Japan. Trailing the technology from USSR, and went through script
                                            transformations, twice.</p>
                                        <p>
                                            Vietnamese now has its own flexibility to express every concepts, ideas,
                                            movements, and feelings that it has been through.</p>
                                        <p>
                                            Inherent to its monosyllabic structure, each sound in Vietnamese is a word,
                                            whether it has a meaning or not, or whether we don't yet know its meaning,
                                            or its meaning got lost in time. And when each of these syllables rings out,
                                            they all convey a sensation, or evoke an emotion to the interlocutor."
                                        </p>
                                        <p class="text-end"><i>
                                                ⎯ Yui Nguyễn</i>
                                        </p>
                                    </div>
                                    <div class="col-sm-4"></div>
                                </div> -->

                                <p>
                                    Typing is a key interaction between us and computer. Typing is a way of using
                                    language. Users forming the words in the mind and put them into life by physically
                                    pressing on keys. Typing reflects how we use language to rationale and navigate in
                                    digital era.
                                </p>

                                <p>
                                    Early 2024, CodeSurfing hosted a research called <a
                                        href="codesurfing.club/tieng-viet/en">"Our Vietnamese Project"</a>. From the
                                    research,
                                    we built a dataset of all the mono-syllables of Vietnamese, extracted from "Từ điển
                                    tiếng Việt"
                                    (Vietnamese dictionary) by Prof. Hoàng Phê. From 30.000 Vietnamese words appear in
                                    the dictionary, we created a dataset of
                                    roughly 6,000 mono-syllables.

                                    While analyzing that monosyllabic dataset, we
                                    recognized a structure of Vietnamese. Despite the alphabetic outerwear, the
                                    Vietnamese body is actually constructed by:
                                </p>
                                <p class="text-center">
                                    <b>
                                        consonant + vowel + consonant
                                    </b>
                                </p>

                                <p>
                                    The current use of alphabetic keyboard (QWERTY) erases that structure and forces
                                    Vietnamese to become a character-based language, instead of a component-based
                                    language. Each part of a Vietnamese syllable carries certain pronunciation and
                                    certain feeling. For example: <b>“phập”</b> starts with <b>“ph”</b> that force us to
                                    breath out
                                    briefly, <b>“ậ”</b> carries the air back in to fill the mouth, then <b>“p”</b> force
                                    the lips and
                                    teeth to close abruptly. All of them together to create “phập”, which means a quick
                                    and exact bite. Think vampire. The QWERTY keyboard erases that syllabic
                                    functionality. And worse, with rules and automation, users are not allowed to form
                                    words that are possible to form and pronounce in Vietnamese but not yet appear in
                                    the dictionary. There are more than new 70,000 syllables like that, compared to
                                    6,000 official syllables. This proves the abundance and flexibility of our language
                                    and suggest endless potential for the growth of Vietnamese.
                                </p>

                                <div class="row">
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="keyboard" href="assets/keyboard/1.webp"><img
                                                src="assets/keyboard/1.webp" width="100%"></a>
                                        <p class="text-center"><i>
                                                Display of keyboard together with its research in Ho Chi Minh City
                                                (09/2024)
                                            </i></p>
                                    </div>
                                    <div class="col-sm-4 px-sm-1">
                                        <a data-fslightbox="keyboard" href="assets/keyboard/3.png"><img
                                                src="assets/keyboard/3.png" width="100%"></a>
                                        <p class="text-center"><i>
                                                Python snippet to extract initial consonants <i>(phu am dau)</i>, ending
                                                consonants <i>(phu am cuoi)</i>, and group vowels <i>(nguyen am)</i>
                                                from all the words in Vietnamese dictionary.
                                            </i></p>
                                    </div>
                                    <div class="col-sm-4">
                                        <a data-fslightbox="keyboard" href="assets/keyboard/4.png"><img
                                                src="assets/keyboard/4.png" width="100%"></a>
                                        <p class="text-center"><i>
                                                A snapshot of the Vietnamese 30,000-word corpus from Vietnamese
                                                dictionary by Prof. Hoang Phe.
                                            </i></p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#wa" aria-expanded="false" aria-controls="wa">
                                <div class="col-sm-8 col-7">
                                    <h4>(2024) 和</h4>
                                    <span class="tag">p5.js</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/wa/1.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="wa" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <div class="row">
                                    <div class="col-sm-4">
                                    </div>
                                    <div class="col-sm-4">
                                        <p>
                                            和 (hoà) is the state of this universe where everything aligns.
                                            — “Thiên thời, địa lợi, nhân hoà” (As above, so below).
                                            <br>和 (hoà) calls for the mediation between human and non-human.
                                            <br>和 (hoà) calls for peace.
                                        </p>
                                        <p><i>
                                                "Thu ăn măng giá, đông ăn trúc.
                                                <br>Xuân tắm hồ sen, hạ tắm ao."
                                            </i>
                                        </p>
                                        <p>和 (hoà) is my ever-echoing chanting for us to immerse back into the nature.
                                        </p>
                                    </div>
                                    <div class="col-sm-4">

                                    </div>
                                </div>
                                <div class="row">
                                    <a class="col-sm-12 col-12 p-2" data-fslightbox="wa" href="assets/wa/1.png"><img
                                            src="assets/wa/1.png" width="100%"></a>

                                    <a class="col-sm-12 col-12 p-2" data-fslightbox="wa" href="assets/wa/0.png"><img
                                            src="assets/wa/0.png" width="100%"></a>

                                    <a class="col-sm-12 col-12 p-2" data-fslightbox="wa" href="assets/wa/2.png"><img
                                            src="assets/wa/2.png" width="100%"></a>
                                </div>

                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#beach-pocket" aria-expanded="false"
                                aria-controls="beach-pocket">
                                <div class="col-sm-8 col-7">
                                    <h4>(2022) Beach Pocket</h4>
                                    <span class="tag">photo, print</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/beach-pocket/4.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="beach-pocket" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p>
                                    First thing I said when a guy took my shirt off was always ⎯ “Am I too skinny?”
                                </p>
                                <p>
                                    From 2019 to 2022, my best friends and I made occasional getaways to the beaches in
                                    Vietnam.
                                    There we swam, sunbathed, read, danced, and radiated under the sun. There I found
                                    comfort in my
                                    own skin. There I realized the beauty of our shapes. The whole process is a healing
                                    journey for
                                    me.
                                </p>
                                <p>
                                    This pocket notebook includes all the portraits and self-portraits that I documented
                                    during the
                                    time.
                                </p>

                                <div class="justify-content-center">
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/1.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/1.png"></a>
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/5.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/5.png"></a>
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/2.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/2.png"></a>
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/6.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/6.png"></a>
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/7.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/7.png"></a>
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/8.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/8.png"></a>
                                    <a data-fslightbox="beach-pocket" href="assets/beach-pocket/3.png"><img
                                            class="beach-pocket-img" src="assets/beach-pocket/3.png"></a>
                                </div>

                                <p>
                                    <br>“My boyfriend once said that I was so tiny
                                    <br>That he could carry me in his pocket anywhere
                                    <br>So put me in your pocket
                                    <br>Use me as your time goes by
                                    <br>Use my body as your late-night canvas

                                    <br>Write on me
                                    <br>Compose on me
                                    <br>Fast on me
                                    <br>Slow on me
                                    <br>Release on me
                                    <br>Spit on me
                                    <br>Piss on me
                                    <br>Bleed on me”


                                    <br><br>✣＊✣

                                    <br>Produced by <a href="https://wedogood.party" target="_blank"
                                        class="link-out">wedogood</a>.
                                    <br>64 pages on risograph using aqua, yellow, flourescent pink.
                                </p>

                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#gai-gia" aria-expanded="false"
                                aria-controls="gai-gia">
                                <div class="col-sm-8 col-7">
                                    <h4>(2022) ガイジャ別府</h4>
                                    <span class="tag">photo, print</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/gai-gia/gaigiabeppu_zine01 copy.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="gai-gia" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <br>
                                <p>
                                    Every year when the cicadas start to sing, I miss Japan dearly, as if a part of
                                    myself had been
                                    buried under the Minami Ishigaki park, where we hung out by the swings, singing, and
                                    smoking.
                                </p>

                                <p>
                                    This summer, as the cicadas are singing again, I invited Cao Mieu to join me in a
                                    conversation
                                    about our Japanese memoirs. But instead of texts, we would reply to each other with
                                    artworks.
                                    Every page is a response to the previous. All communication takes place only within
                                    these pages.
                                </p>

                                <p>
                                    I lost my residence card years ago. Mieu still has hers, so she will hereby board
                                    the page
                                    first.
                                </p>


                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine01.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine01.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine02.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine02.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine03.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine03.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine04.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine04.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine05.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine05.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine06.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine06.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine061.png"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine061.png"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine07.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine07.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine08.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine08.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine09.jpeg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine09.jpeg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine10.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine10.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine11.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine11.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine12.jpg"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine12.jpg"></a>
                                <a data-fslightbox="beppu" href="assets/gai-gia/gaigiabeppu_zine13.png"><img
                                        style="width:70%" src="assets/gai-gia/gaigiabeppu_zine13.png"></a>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#dick" aria-expanded="false"
                                aria-controls="dick">
                                <div class="col-sm-8 col-7">
                                    <h4>(2022) live. laugh. dick.</h4>
                                    <span class="tag">Python, print</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <img src="assets/live-laugh-dicks/1.png" class="thumb">
                                </div>
                            </button>
                        </h2>
                        <div id="dick" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p>
                                    Back in April, wedogood invited me to join their zine with the theme of “Love
                                    Machine. Machine
                                    Love”. This poster is a
                                    stand-alone
                                    version of my work in the zine. More than a collection of quirky-looking toys, It
                                    reflects our
                                    current perception of sex toy design (dildos and butt plugs in particular) while
                                    suggesting new
                                    boundaries for toy design.
                                </p>

                                <div class="row py-sm-2">
                                    <div class="col-sm-6 px-sm-1">
                                        <a data-fslightbox="dick" href="assets/live-laugh-dicks/1.png"><img
                                                src="assets/live-laugh-dicks/1.png" width=100%></a>
                                    </div>
                                    <div class="col-sm-6 px-sm-1"><a data-fslightbox="dick"
                                            href="assets/live-laugh-dicks/2.png"><img
                                                src="assets/live-laugh-dicks/2.png" width=100%></a>
                                    </div>
                                </div>

                                <div class="row py-sm-2">
                                    <div class="col-sm-6 px-sm-1">

                                        <a data-fslightbox="dick" href="assets/live-laugh-dicks/3.png"><img
                                                src="assets/live-laugh-dicks/3.png" width=100%></a>
                                    </div>
                                    <div class="col-sm-6 px-sm-1">
                                        <a data-fslightbox="dick" href="assets/live-laugh-dicks/4.png"><img
                                                src="assets/live-laugh-dicks/4.png" width=100%></a>
                                    </div>
                                </div>

                                <p>
                                    After being trained with 3000 photos of toys, the generative model clearly gets the
                                    idea that a
                                    sex toy needs to be pointed (of course). But it takes the idea further by
                                    re-imagining toys with
                                    multiple heads, and toys with irregular shapes or shapes that are different from
                                    cylinders.
                                    Several generated samples also include toys that are bound together since e-commerce
                                    often
                                    places their toys next to each other in product photos. If such an arrangement
                                    stimulates the
                                    buyer, then why not include them in the real product design? Many of the generated
                                    samples also
                                    propose getting rid of the inside of the toys as it is not a significant feature.
                                    They suggest
                                    void, disjoint parts, transparent material, and anything else but the common solid
                                    shape.

                                    Pleasure has its own curiosity. And maybe toys for pleasure should also be more
                                    suggestive,
                                    rather than adaptive.

                                </p>
                                <p>

                                    This project is built on my custom GAN model, inspired by StyleGAN2. The StyleGAN2
                                    architecture
                                    itself is gigantic. To afford training, I made multiple adjustments in the
                                    architecture,
                                    including downsizing the output image size to 128x128. This seriously damaged the
                                    print quality
                                    but Risograph helped me bypass that. I also divided the training into multiple
                                    sessions + used
                                    the Tensorflow Data Dataset & Tensorflow Record to optimize the whole training
                                    speed. All are
                                    for this project to be run on the free resource of Google Colab, which has a limited
                                    quota every
                                    day. So much engineering just to have more dicks while paying less 🥴

                                </p>


                                <div class="row">
                                    <div class="col-sm-4 px-sm-2"><a data-fslightbox="dick"
                                            href="assets/live-laugh-dicks/6.gif"><img
                                                src="assets/live-laugh-dicks/6.gif" width=100%></a>
                                    </div>
                                    <div class="col-sm-4 px-sm-2"> <a data-fslightbox="dick"
                                            href="assets/live-laugh-dicks/7.png"><img
                                                src="assets/live-laugh-dicks/7.png" width=100%></a></div>
                                    <div class="col-sm-4 px-sm-2"><a data-fslightbox="dick"
                                            href="assets/live-laugh-dicks/8.gif"><img
                                                src="assets/live-laugh-dicks/8.gif" width=100%></a></div>
                                </div>

                                <p>
                                    <br>WHY RISOGRAPH?

                                    <br><br>Generative art is not for size queen. Artworks generated from ML model
                                    struggle to have
                                    a good
                                    resolution. A simple image of 300x300 would take 90,000 units when being flattened.
                                    It means
                                    that a larger output images come with a larger cost of computation. It often
                                    requires days of
                                    training on expensive GPU. When it comes to printing, this limit in output results
                                    in pixelating
                                    details, blurry edges, and inconsistent separation between object and background.
                                    Not only that,
                                    generative images oftentimes have the checkerboard effect, as a result that the
                                    machine
                                    “painted” each pixel independently and lack of perception of the image as a whole.

                                </p>
                                <p>
                                    In order to produce this digital artwork in high-quality print (A3), we first put
                                    the 128x128
                                    generated images through a half-toned treatment - a technique to simulate the image
                                    tone through
                                    dots. By carefully adjusting the dot size, we gave the pixelated images a sharper
                                    optic illusion
                                    in general. A subtly similar pair of aqua ink and purple paper were then chosen to
                                    let the
                                    half-toned dots blend smoothly with the background. The various size of dots +
                                    different % of
                                    ink embrace the blurry edge. The aqua ink also expands optically when we tilt the
                                    poster to
                                    different light direction. Object edges “fade” gradually into paper like chalk. The
                                    drawback of
                                    pixelating and not having sharp edges is now a compliment toward the initial
                                    inspiration of
                                    stains.
                                </p>
                                <div class="row">
                                    <div class="col-sm-6 px-sm-2"><a data-fslightbox="dick"
                                            href="assets/live-laugh-dicks/9.png"><img
                                                src="assets/live-laugh-dicks/9.png" width=100%></a>
                                    </div>
                                    <div class="col-sm-6 px-sm-2"> <a data-fslightbox="dick"
                                            href="assets/live-laugh-dicks/10.png"><img
                                                src="assets/live-laugh-dicks/10.png" width=100%></a></div>

                                </div>


                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- <section class="py-2">
                <h2><i>⎯ Teaching</i></h2>
                <div class="accordion px-sm-4" id="teach">
                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#sensory" aria-expanded="false"
                                aria-controls="sensory">
                                <div class="col-sm-8 col-7">
                                    <h4>(2023) Khởi đầu p5.js</h4>
                                    <span class="tag">p5.js</span>
                                </div>
                            </button>
                        </h2>
                        <div id="sensory" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <div class="row">
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/1.png"><img
                                            src="assets/wa/1.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/0.png"><img
                                            src="assets/wa/0.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/2.png"><img
                                            src="assets/wa/2.png" width="100%"></a>
                                </div>

                            </div>
                        </div>
                    </div>
                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#sensory" aria-expanded="false"
                                aria-controls="sensory">
                                <div class="col-sm-8 col-7">
                                    <h4>(2024) Nhìn mình</h4>
                                    <span class="tag">p5.js</span>
                                </div>
                            </button>
                        </h2>
                        <div id="sensory" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <div class="row">
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/1.png"><img
                                            src="assets/wa/1.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/0.png"><img
                                            src="assets/wa/0.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/2.png"><img
                                            src="assets/wa/2.png" width="100%"></a>
                                </div>

                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#sensory" aria-expanded="false"
                                aria-controls="sensory">
                                <div class="col-sm-8 col-7">
                                    <h4>(2023) Sensory Narratives</h4>
                                    <span class="tag">p5.js</span>
                                </div>
                            </button>
                        </h2>
                        <div id="sensory" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <div class="row">
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/1.png"><img
                                            src="assets/wa/1.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/0.png"><img
                                            src="assets/wa/0.png" width="100%"></a>
                                    <a class="col-sm-4 col-12 p-2" data-fslightbox="wa" href="assets/wa/2.png"><img
                                            src="assets/wa/2.png" width="100%"></a>
                                </div>

                            </div>
                        </div>
                    </div>
                </div>
            </section> -->

            <section class="py-2">
                <h2><i>⎯ Early Programming Practice</i></h2>
                <div class="accordion px-sm-4" id="tech">
                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#wes-anderson" aria-expanded="false"
                                aria-controls="wes-anderson">
                                <div class="col-sm-8 col-7">
                                    <h4>(2021) Watching Wes Anderson</h4>
                                    <span class="tag">Python, data analysis</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <!-- <img src="assets/wes-anderson/aqua_1.png" class="thumb"> -->
                                </div>
                            </button>
                        </h2>
                        <div id="wes-anderson" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">

                                <div class="row">
                                    <div class="col-sm-4 px-sm-2">
                                    </div>
                                    <div class="col-sm-4 px-sm-2">
                                        <p>
                                            The normal way of watching a movie involves experiencing it frame by
                                            frame, unfolding linearly over time as visual elements build upon one
                                            another. This project reimagines that approach, offering a single,
                                            comprehensive view to explore the visual essence of Wes Anderson's films.
                                        </p>
                                        <p>
                                            To achieve this, each frame of the film was transformed from its original
                                            rectangular shape (720x1280) into a long, compressed strip (1x921,600
                                            pixels). These strips were then stacked vertically to create the final
                                            artwork. As a result, the movie unfolds vertically from top to bottom,
                                            representing the progression from beginning to end. Horizontally, our eyes
                                            trace a zigzag pattern, moving through individual scenes from left to right
                                            and top to bottom.
                                        </p>
                                    </div>
                                    <div class="col-sm-4 px-sm-2">
                                    </div>
                                </div>

                                <!-- <a data-fslightbox="anderson" href="assets/wes-anderson/aqua_1.png"><img
                                        src="assets/wes-anderson/aqua_1.png" width="50%" class="mx-auto d-block"></a> -->

                                <div class="row">
                                    <div class=" col-sm-4 px-sm-2">
                                        <hr>
                                        <h4>
                                            Moonrise Kingdom (2012)
                                        </h4>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/moon_1.png"><img
                                                src="assets/wes-anderson/moon_1.png" width="100%"
                                                class="mx-auto d-block"></a>
                                        <p>
                                            Moonrise Kingdom is divided into two distinctive palettes: before the storm
                                            and
                                            after the storm.
                                            The “before the storm” embraces the warm colors of yellow, green, and brown,
                                            with
                                            scenes mostly
                                            shot in bright sunlight while the “after the storm” rages in cooler shades
                                            of blue
                                            and teal,
                                            with lots of scenes without the sun or even in the dark.
                                        </p>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/moon_1.png"><img
                                                src="assets/wes-anderson/moon_1.png" width="100%"></a>

                                        <a data-fslightbox="anderson" href="assets/wes-anderson/moon_2.png"><img
                                                src="assets/wes-anderson/moon_2.png" width="100%"></a>

                                        <p>
                                            The transition from the bright color to the darker one doesn’t follow the
                                            change of
                                            nature (the
                                            arrival of the storm) in the movie. It, however, follows the transition of
                                            the
                                            characters’
                                            emotions. The change started right after Sam and Suzy got caught by the
                                            beach. The
                                            following
                                            scene of Suzy’s conversation with her mom immediately takes the sunlight out
                                            and
                                            drowns the
                                            movie in the cold tub. Perhaps, the movie’s real storm already raged after
                                            that
                                            conversation.
                                        </p>

                                        <a data-fslightbox="anderson" href="assets/wes-anderson/moon_6.png"><img
                                                src="assets/wes-anderson/moon_6.png" width="100%"></a>
                                    </div>

                                    <div class="col-sm-4 px-sm-2">
                                        <hr>
                                        <h4>
                                            The Grand Budapest Hotel (2014)
                                        </h4>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/hotel_1.png"><img
                                                src="assets/wes-anderson/hotel_1.png" width="100%"
                                                class="mx-auto d-block"></a>
                                        <p>
                                            The movie has many noticeable black columns that run vertically. Their
                                            widths vary
                                            in the
                                            beginning, then become consistent as the movie goes on. These black columns
                                            are
                                            created from the
                                            black margin of the frames. Different size of black margin signifies
                                            different
                                            screen ratios. In
                                            fact, Wes Anderson intentionally used different screen ratios to mimic
                                            different
                                            eras’ cinematic
                                            styles. The 80’s ⎯ 1.85 : 1, The 60’s ⎯ 2.40 : 1, The 30’s ⎯ 1.37:1.
                                        </p>


                                        <a data-fslightbox="anderson" href="assets/wes-anderson/hotel_2.png"><img
                                                src="assets/wes-anderson/hotel_2.png" width="100%"></a>
                                        <p>
                                            <br>The movie is clearly divided into blocks of colors. Each group of scenes
                                            is in
                                            one
                                            distinctive
                                            palette of color. The transition of color is both more extreme and playful
                                            than in
                                            his early
                                            works - Moonrise Kingdom and The Life Aquatic of Steve Zissou.
                                        </p>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/hotel_3.png"><img
                                                src="assets/wes-anderson/hotel_3.png" width="100%"></a>
                                    </div>

                                    <div class="col-sm-4 px-sm-2">
                                        <hr>
                                        <h4>
                                            Isle of Dogs (2018)
                                        </h4>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/dog_1.png"><img
                                                src="assets/wes-anderson/dog_1.png" width="100%"
                                                class="mx-auto d-block"></a>


                                        <p>
                                            Continued with the idea of using colors to define space for characters’
                                            emotions,
                                            Isle of Dogs
                                            used extreme colors, black and white, to depict two different groups of
                                            scenes: the
                                            trash island
                                            and the city hall. Yellow strips that run horizontally between them are
                                            Tracy
                                            Walker. She brings
                                            light to the revolution of Atari and the dogs.
                                        </p>

                                        <a data-fslightbox="anderson" href="assets/wes-anderson/dog_2.png"><img
                                                src="assets/wes-anderson/dog_2.png" width="100%"></a>

                                        <p>
                                            Several groups of scenes in Isle of Dogs maintain a fixed layout, with both
                                            characters and the
                                            camera making minimal moves. For example, in the white strip area in the
                                            middle,
                                            we
                                            can see that
                                            the black area (the characters) stays in place for several continuous
                                            scenes.
                                            This
                                            can be the
                                            effect of stop motion, where continuous scenes have very subtle changes, so
                                            the
                                            audiences can
                                            really focus on such change and the “stop-motion delay” between the change.
                                            For
                                            example, the
                                            making sushi scene.

                                            However, when considering other movies by Wes Anderson, The Grand Budapest
                                            Hotel
                                            also has this
                                            same pattern. Many scenes in the movie, especially scenes where characters
                                            discuss,
                                            have very
                                            minimal camera movement. So rather than highlighting the effect of stop
                                            motion,
                                            in
                                            these scenes
                                            of Isle of Dog, Wes Anderson is leveraging stop motion to achieve his own
                                            distinctive technique.
                                            They play out so well and compliment each other.
                                        </p>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/dog_3.png"><img
                                                src="assets/wes-anderson/dog_3.png" width="100%"></a>
                                        <p>
                                            <i>Isle of Dogs</i>
                                        </p>
                                        <a data-fslightbox="anderson" href="assets/wes-anderson/dog_4.png"><img
                                                src="assets/wes-anderson/dog_4.png" width="100%"></a>
                                        <p>
                                            <i>The Grand Budapest Hotel</i>
                                        </p>
                                    </div>
                                </div>






                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#vision" aria-expanded="false"
                                aria-controls="vision">
                                <div class="col-sm-8 col-7">
                                    <h4>(2020) Enhanced Super Resolution GAN</h4>
                                    <span class="tag">Python, machine learning</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <!-- <img src="assets/esrgan/1.jpeg" class="thumb"> -->
                                </div>
                            </button>
                        </h2>
                        <div id="vision" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p>
                                    View project on <a href="https://github.com/nhanphan0411/VISION2020"
                                        class="link-out" target="blank_">Github</a>
                                </p>
                                <a data-fslightbox="vision" href="assets/esrgan/1.jpeg"><img src="assets/esrgan/1.jpeg"
                                        width="100%"></a>
                                <p>
                                    VISION2020 aims at recovering a high resolution image from a low resolution one. The
                                    project is
                                    based largely on the excellent research of Xintao Wang, et al. on ESRGAN (2018) and
                                    their
                                    implementation using Pytorch. Inspired from the research, my version of ESRGAN is
                                    optimized and
                                    built entirely on Tensorflow 2.0. It successfully resizes the image up to x64 on
                                    square area.
                                </p>
                                <p>
                                    Single image super-resolution (SISR), as a fundamental low-level vision problem, has
                                    attracted
                                    increasing attention in the research community and AI companies. SISR aims at
                                    recovering a
                                    high-resolution (HR) image from a single low-resolution (LR) one. Since the pioneer
                                    work of
                                    SRCNN
                                    proposed by Dong et al., deep convolution neural network (CNN) approaches have
                                    brought
                                    prosperous
                                    development. Various network architecture designs and training strategies have
                                    continuously
                                    improved
                                    the SR performance.
                                </p>
                                <p>

                                    The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that
                                    is capable of
                                    generating realistic textures during single image super-resolution. However, the
                                    hallucinated
                                    details are often accompanied with unpleasant artifacts. To further enhance the
                                    visual quality,
                                    we
                                    thoroughly study three key components of SRGAN - network architecture, adversarial
                                    loss and
                                    perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN).
                                </p>
                                <p>
                                    In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without
                                    batch
                                    normalization
                                    as the basic network building unit. Moreover, we borrow the idea from relativistic
                                    GAN to let
                                    the
                                    discriminator predict relative realness instead of the absolute value. Finally, we
                                    improve the
                                    perceptual loss by using the features before activation, which could provide
                                    stronger
                                    supervision
                                    for brightness consistency and texture recovery. Benefiting from these improvements,
                                    the
                                    proposed
                                    ESRGAN achieves consistently better visual quality with more realistic and natural
                                    textures than
                                    SRGAN.
                                </p>

                                <a data-fslightbox="vision" href="assets/esrgan/2.png"><img src="assets/esrgan/2.png"
                                        width="100%"></a>

                                <p>
                                    fig1 ⎯ (x4 per dimension) generated image successfully retains small detail like the
                                    strip at
                                    the shoulder area and the human head.
                                </p>
                                <a data-fslightbox="vision" href="assets/esrgan/3.png"><img src="assets/esrgan/3.png"
                                        width="100%"></a>
                                <p>
                                    fig2 ⎯ (x4 per dimension) Natural features like eyes are well reconstructed.
                                </p>
                                <a data-fslightbox="vision" href="assets/esrgan/4.png"><img src="assets/esrgan/4.png"
                                        width="100%"></a>
                                <p>
                                    fig3 ⎯ (x8 per dimension) Double challenging, then model successfully reconstruct
                                    pattern and
                                    lines.
                                </p>
                                <a data-fslightbox="vision" href="assets/esrgan/5.png"><img src="assets/esrgan/5.png"
                                        width="100%"></a>
                                <p>
                                    fig4 ⎯ (x8 dimension) Letters are brought back to vision.
                                </p>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#viet-ocr" aria-expanded="false"
                                aria-controls="viet-ocr">
                                <div class="col-sm-8 col-7">
                                    <h4>(2020) Vietnamese Handwritten OCR</h4>
                                    <span class="tag">Python, machine learning</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <!-- <img src="assets/ocr/1.png" class="thumb"> -->
                                </div>
                            </button>
                        </h2>
                        <div id="viet-ocr" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p>
                                    View project on <a href="https://github.com/nhanphan0411/viet-ocr" class="link-out"
                                        target="blank_">Github 👾</a>
                                </p>
                                <p>
                                    Optical Character Recognition is one active field that bridges between computer
                                    vision and
                                    natural language processing. As much as the field emerges within machine learning
                                    community, it
                                    still performs poorly on local language, including Vietnamese with our distinctive
                                    symbol (ễ, ẩ,
                                    ứ for example). The lack of data is one of the main reason behind it. This project
                                    is a submission to a hackathon hosted by
                                    Cinnamon AI on that challenge of Vietnamese OCR. The dataset
                                    includes all the address written in Vietnamese. The model can be immediately apply
                                    in post
                                    service to alleviate the need of manual input.
                                </p>

                                <a data-fslightbox="ocr" href="assets/ocr/1.png"><img src="assets/ocr/1.png" width="50%"
                                        class="mx-auto d-block"></a>

                                <p>
                                    ⎯ EVALUATION
                                </p>
                                <p>
                                <ul>
                                    <li>Character Error Rate: 0.04</li>
                                    <li>Word Error Rate: 0.14</li>
                                    <li>Sentence Error Rate: 0.82</li>
                                </ul>
                                </p>
                                </p>
                                <p>
                                    <i>The hackathon's leader score is 0.1x on the Word Error Rate.
                                        Other metric results were not disclosed.</i>
                                </p>
                                <p>
                                    ⎯ SAMPLE PREDICTIONS <i>(T: True Label, P: Prediction)</i>
                                </p>
                                <a data-fslightbox="ocr" href="assets/ocr/2.png"><img src="assets/ocr/2.png" width="50%"
                                        class="mx-auto d-block"></a>
                                <p>
                                    ⎯ DATA PREPROCESSING: Using OpenCV with 3 phases
                                <ol>
                                    <li>Thresholding</li>
                                    <li>Resize to 128x1024</li>
                                    <li>Remove Recursive (reference to A. Vinciarelli and J. Luettin)</li>
                                </ol>
                                </p>
                                <p style="text-align: center; margin-bottom: 0">Raw data</p>
                                <a data-fslightbox="ocr" href="assets/ocr/3.png"><img src="assets/ocr/3.png" width="50%"
                                        class="mx-auto d-block"></a>
                                <p style="text-align: center; margin-bottom: 0">Processed data</p>
                                <a data-fslightbox="ocr" href="assets/ocr/4.png"><img src="assets/ocr/4.png" width="50%"
                                        class="mx-auto d-block"></a>
                                <p>
                                    ⎯ MODELLING
                                <ul>
                                    <li>CRNN + CTC Loss is used to solve this challenge.</li>
                                    <li>CNN blocks with skip connections (inspired by ResNet50) are used to extract the
                                        features from input images.</li>
                                    <li>The extracted feature map will be then passed through the LSTM layers.</li>
                                </ul>
                                </p>
                                <a data-fslightbox="ocr" href="assets/ocr/5.png"><img src="assets/ocr/5.png" width="50%"
                                        class="mx-auto d-block"></a>
                                <br>
                                <p style="text-align: center; margin-bottom: 0"><i>Training Log</i></p>
                                <a data-fslightbox="ocr" href="assets/ocr/6.png"><img src="assets/ocr/6.png" width="50%"
                                        class="mx-auto d-block"></a>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <h2 class="accordion-header">
                            <button class="accordion-button collapsed justify-content-between" type="button"
                                data-bs-toggle="collapse" data-bs-target="#amazon" aria-expanded="false"
                                aria-controls="amazon">
                                <div class="col-sm-8 col-7">
                                    <h4>(2019) Understand The Amazon From Above</h4>
                                    <span class="tag">Python, machine learning</span>
                                </div>
                                <div class="col-sm-2 col-2 ps-sm-1 ps-3">
                                    <!-- <img src="assets/amazon/2.png" class="thumb"> -->
                                </div>
                            </button>
                        </h2>
                        <div id="amazon" class="accordion-collapse collapse" data-bs-parent="#project">
                            <div class="accordion-body">
                                <p>View project on <a
                                        href="https://colab.research.google.com/drive/1s8iFtj7D4D0BNlsR7P9hvfzsqV8XhjTD?authuser=1"
                                        class="link-out" target="blank_">Google Colaboratory</a> 👾</p>
                                <p>This project is an entry of the corresponding <a
                                        href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data"
                                        class="link-out">Kaggle competition.</a></p>

                                <img src="assets/amazon/1.jpg" width="100%">
                                <br><br>
                                <p>
                                    Every minute, the world loses an area of forest the size of 48 football fields. And
                                    deforestation in the Amazon Basin accounts for the largest share, contributing to
                                    reduced
                                    biodiversity, habitat loss, climate change, and other devastating effects. But
                                    better data about
                                    the location of deforestation and human encroachment on forests can help governments
                                    and local
                                    stakeholders respond more quickly and effectively.
                                </p>

                                <p>
                                    From a dataset contains more than 40.000 images, this analysis uses Deep Learning to
                                    classify the spatial images of the Amazon forest
                                    taken by the satellite. From that, it hopes to shed a light on understanding how the
                                    forest
                                    has change naturally and manually. Thus, help preventing deforestation.
                                </p>

                                <p>⎯ SAMPLE PREDICTION</p>
                                <a data-fslightbox="amazon" href="assets/amazon/5.png"><img src="assets/amazon/5.png"
                                        width="100%"></a>

                                <p class="text-center"><i>Evaluation</i></p>
                                <img src="assets/amazon/3.png" width="40%" class="mx-auto d-block">
                                <img src="assets/amazon/4.png" width="40%" class="mx-auto d-block">

                                <p>⎯ SOME CHALLENGES</p>
                                <ol>
                                    <li>
                                        <p>Multi-label: Each image is labeled with multiple tags (at least 2, at max 9).
                                            The
                                            tags fall
                                            into
                                            17 categories, which are the forest landscape types. Since the tags in each
                                            label
                                            are mutually
                                            exclusive, they are treated as multiple binary classification problems.
                                            Thus, binary
                                            cross-entropy
                                            are chosen to be the loss function.
                                        </p>
                                    </li>
                                    <li>

                                        <p>
                                            Imbalance: The dataset is severely imbalance with tags like Primary or
                                            Agriculture appear in
                                            90%
                                            of the dataset. While other tags like Blooming or Conventional Mine can only
                                            be seen
                                            in less
                                            than
                                            500 observations (even less than 100 for Burn Down).
                                        </p>
                                        <p>
                                            In the first base-line experiment, the model was totally bias toward the
                                            major tags.
                                            It predicts
                                            the
                                            major tags to appear in every data and almost never made a prediction with
                                            the minor
                                            tags.
                                            To tackle the problem of imbalance dataset, evaluation metrics must be
                                            chosen
                                            carefully. F2 is
                                            chosen to be the main metrics to evaluate the training. It watches over the
                                            harmonic
                                            mean
                                            between
                                            the Precision and Recall while favors Recall specifically. In other word, it
                                            is the
                                            attempt to
                                            reduce the number of False Negative, where the model fails to identify the
                                            absence
                                            of a tag.
                                        </p>
                                    </li>
                                    <li>
                                        <p>
                                            Optimization: 400.000 images, a CNN model, and Google Colab's limited
                                            resource
                                            do not seem
                                            to
                                            mix well together. The training was slow at first and interupted often.
                                            Several
                                            improvements,
                                            mostly
                                            on the Tensorflow pipeline, were conducted to speed up the training:
                                            Using TFRecord to convert the raw images into byte-like data to reduce the
                                            amount of
                                            time
                                            spending
                                            on reading data from their paths.
                                        </p>
                                        <p>
                                            Using tf.data.Dataset with shuffle, map, batch, prefetch to optimize the
                                            reading
                                            data process by
                                            redistributing the tasks for agents to work concurrently, thus, avoid
                                            bottleneck. An
                                            attempt to
                                            use
                                            cache was also made but failed due to the limited RAM.
                                        </p>
                                        <p>
                                            Processing image with Tensorflow: The dataset contains images in JPG - RGBA.
                                            The
                                            built-in decode
                                            function tf.io.decode_jpeg only works on 1 or 3-channel image. Attempt on
                                            encoding a
                                            JPG RGBA
                                            image
                                            returns black black and black. We need a tensorflow encoding function to
                                            work in
                                            this part
                                            because
                                            the pipeline is built entirely on Tensor for the optimization purpose.
                                            To tackle the problem, the raw images were first read by Matplotlib then
                                            converted
                                            into
                                            byte-like
                                            and wrote into TFRecords. When reading the data from TF Record, instead of
                                            using the
                                            built-in
                                            decode
                                            image function, we use tf.io.parse_tensor following with reshaping.
                                        </p>
                                    </li>
                                </ol>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

        </div>
    </div>
</body>

<script src="assets/portrait/sketch.js"></script>
<script src="fslightbox.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js"
    integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js"
    integrity="sha384-0pUGZvbkm6XF6gxjEnlmuGrJXVbNuzT9qBBavbLwCsOGabYfZo0T0to5eqruptLy"
    crossorigin="anonymous"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        const images = document.querySelectorAll("img");
        images.forEach(image => {
            image.setAttribute("loading", "lazy");
        });
    });
</script>

</html>